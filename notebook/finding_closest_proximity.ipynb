{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=[[147, 123], [556, 207]]\n",
    "f2=[[146, 122], [556, 209], [653, 174]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= euclidean_distances(f1,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.41421356, 417.94377612, 508.56366366],\n",
       "       [418.71828238,   2.        , 102.45974819]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val,max_val = x.min(),x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = (x-min_val)/(max_val-min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.8213152207434937, 1.0]\n",
      ":@@@@@@@@@@@@@@@@@@@\n",
      "[0.8228423963278771, 0.0011550568328700386, 0.19924212598743657]\n",
      ":@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(normalized)):\n",
    "    print(list(normalized[i]))\n",
    "    print(\":@@@@@@@@@@@@@@@@@@@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      ":@@@@@@@@@@@@@@@@@@@\n",
      "1\n",
      ":@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(normalized)):\n",
    "    print(np.argmin(normalized[i]))\n",
    "    print(\":@@@@@@@@@@@@@@@@@@@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_proximity_detecton(frame1,frame2,proximity_threshold):\n",
    "    distanct_matrix = euclidean_distances(frame1,frame2)\n",
    "    min_val,max_val = distanct_matrix.min(),distanct_matrix.max()\n",
    "    distanct_matrix_normalized = (distanct_matrix-min_val)/(max_val-min_val)\n",
    "    proxy_results = {}\n",
    "    proximity_values = []\n",
    "    for i in range(len(distanct_matrix_normalized)):\n",
    "        min_val = np.argmin(distanct_matrix_normalized[i])\n",
    "        if distanct_matrix_normalized[i][min_val] < proximity_threshold:\n",
    "            proxy_results[i]=min_val\n",
    "            proximity_values.append(distanct_matrix_normalized[i][min_val])\n",
    "        else:\n",
    "            proxy_results[i]=None\n",
    "            proximity_values.append(distanct_matrix_normalized[i][min_val])\n",
    "    return proxy_results,proximity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 1}, [0.0, 0.0011550568328700386])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_proximity_detecton(f1,f2,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Frame:\n",
    "    def __init__(self, frame_number):\n",
    "        self.frame_number = frame_number\n",
    "        self.frame_array = None\n",
    "        self.face_info = []\n",
    "\n",
    "    def insert_face_count(self, face_count):\n",
    "        self.face_count = face_count\n",
    "\n",
    "    def insert_frame_array(self, frame_array):\n",
    "        self.frame_array = frame_array\n",
    "\n",
    "    def insert_face_info(self, face_boxes, facial_features):\n",
    "        for box, feature in zip(face_boxes, facial_features):\n",
    "            self.face_info.append(\n",
    "                {\"face_box\": box,\n",
    "                 \"emotion\": feature['emotion_output'],\n",
    "                 \"age\": feature['age_output'],\n",
    "                 \"sex\": feature['gender_output']})\n",
    "\n",
    "    def get_all_face_positions(self):\n",
    "        if len(self.face_info) > 0:\n",
    "            face_boxes = []\n",
    "            for face in self.face_info:\n",
    "                x,y,w,h= face['face_box']\n",
    "                face_boxes.append([x,y])\n",
    "            return face_boxes\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_name, video_path, total_frames, fps):\n",
    "        self.name = video_name\n",
    "        self.path = video_path\n",
    "        self.total_frames = total_frames\n",
    "        self.fps = fps\n",
    "        self.batch_size = int(total_frames / fps)\n",
    "        self.frame_computer = []\n",
    "        self.all_frames = []\n",
    "\n",
    "    def put_frame(self, frame: Frame):\n",
    "        self.frame_computer.append(frame)\n",
    "        if len(self.frame_computer) >= self.batch_size:\n",
    "            yield self.frame_computer\n",
    "            self.all_frames.extend(self.frame_computer)\n",
    "            self.frame_computer = []\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_all_frames(self):\n",
    "        return self.all_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/tmp/video_obj.pkl','rb') as fp:\n",
    "    video = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[303, 460], [100, 654], [481, 770], [194, 319], [524, 439]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.get_all_frames()[0].get_all_face_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-480f52be7ba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_face_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_face_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "f1 = video.get_all_frames()[4].get_all_face_positions()\n",
    "f2 = video.get_all_frames()[5].get_all_face_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147, 123], [556, 207]]\n",
      "[[146, 122], [556, 209], [653, 174]]\n"
     ]
    }
   ],
   "source": [
    "print(f1)\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[303, 460], [100, 654], [481, 770], [194, 319], [524, 439]] ---> [[304, 460], [102, 655], [481, 771], [196, 321], [523, 441]]\n",
      "({0: 0, 1: 1, 2: 2, 3: 3, 4: 4}, [0.0, 0.002312921264906562, 0.0, 0.0034213393236765944, 0.002312921264906562])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "10\n",
      "[[304, 460], [102, 655], [481, 771], [196, 321], [523, 441]] ---> [[304, 461], [102, 661], [480, 770], [196, 314], [521, 441]]\n",
      "({0: 0, 1: 1, 2: 2, 3: 3, 4: 4}, [0.0, 0.009300851571950592, 0.0007705077725442112, 0.01116102188634071, 0.0018601703143901183])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "15\n",
      "[[304, 461], [102, 661], [480, 770], [196, 314], [521, 441]] ---> [[304, 465], [104, 658], [481, 770], [196, 312], [524, 447]]\n",
      "({0: 0, 1: 1, 2: 2, 3: 3, 4: 4}, [0.005577179521656118, 0.004843875738714247, 0.0, 0.0018590598405520394, 0.010611892692590802])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "20\n",
      "[[304, 465], [104, 658], [481, 770], [196, 312], [524, 447]] ---> [[303, 463], [197, 320], [102, 655], [479, 771], [524, 446]]\n",
      "({0: 0, 1: 2, 2: 3, 3: 1, 4: 4}, [0.0022965383440566836, 0.004840954154974755, 0.0022965383440566836, 0.013121240910540287, 0.0])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "25\n",
      "[[303, 463], [197, 320], [102, 655], [479, 771], [524, 446]] ---> [[304, 463], [199, 318], [104, 660], [479, 772], [524, 444]]\n",
      "({0: 0, 1: 1, 2: 2, 3: 3, 4: 4}, [0.0, 0.003438475933181901, 0.008246587161334805, 0.0, 0.0018805649329115082])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "30\n",
      "[[304, 463], [199, 318], [104, 660], [479, 772], [524, 444]] ---> [[305, 467], [105, 664], [479, 774], [199, 318], [525, 446]]\n",
      "({0: 0, 1: 3, 2: 1, 3: 2, 4: 4}, [0.007705245558666919, 0.0, 0.007705245558666919, 0.0037375930952594197, 0.004178756116616954])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "35\n",
      "[[305, 467], [105, 664], [479, 774], [199, 318], [525, 446]] ---> [[307, 471], [103, 672], [198, 318], [523, 452], [479, 768]]\n",
      "({0: 0, 1: 1, 2: 4, 3: 2, 4: 3}, [0.0064944935608583654, 0.01355375276823598, 0.00935230308523324, 0.0, 0.009959371029976107])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "40\n",
      "[[307, 471], [103, 672], [198, 318], [523, 452], [479, 768]] ---> [[306, 470], [199, 317], [105, 677], [526, 451], [479, 768]]\n",
      "({0: 0, 1: 2, 2: 1, 3: 3, 4: 4}, [0.0026640583503795066, 0.010144431968636207, 0.0026640583503795066, 0.00595701556747453, 0.0])\n",
      "\n",
      "\n",
      "######################################################################\n",
      "45\n",
      "[[306, 470], [199, 317], [105, 677], [526, 451], [479, 768]] ---> [[307, 471], [106, 680], [192, 307], [525, 452], [479, 768]]\n",
      "({0: 0, 1: 2, 2: 1, 3: 3, 4: 4}, [0.002604263805596706, 0.022478281800462577, 0.005823310900656532, 0.002604263805596706, 0.0])\n",
      "\n",
      "\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "all_frames = video.get_all_frames()\n",
    "for i in range(len(all_frames)-1):\n",
    "    print(all_frames[i].frame_number)\n",
    "    print(all_frames[i].get_all_face_positions(),'--->',all_frames[i+1].get_all_face_positions())\n",
    "    print(face_proximity_detecton(all_frames[i].get_all_face_positions(),all_frames[i+1].get_all_face_positions(),0.1))\n",
    "    print(\"\\n\")\n",
    "    print(\"######################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = None\n",
    "f2 = None\n",
    "for i in range(len(all_frames)):\n",
    "    if all_frames[i].frame_number == 35:\n",
    "        f1=all_frames[i]\n",
    "        f2 = all_frames[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'face_box': [305, 467, 187, 249],\n",
       "  'emotion': {'value': 'sadness', 'probability': '0.91'},\n",
       "  'age': {'value': 'young', 'probability': '1.00'},\n",
       "  'sex': {'value': 'male', 'probability': '1.00'}},\n",
       " {'face_box': [105, 664, 193, 260],\n",
       "  'emotion': {'value': 'happiness', 'probability': '0.51'},\n",
       "  'age': {'value': 'young', 'probability': '1.00'},\n",
       "  'sex': {'value': 'female', 'probability': '1.00'}},\n",
       " {'face_box': [479, 774, 168, 226],\n",
       "  'emotion': {'value': 'happiness', 'probability': '1.00'},\n",
       "  'age': {'value': 'middle', 'probability': '0.99'},\n",
       "  'sex': {'value': 'female', 'probability': '0.94'}},\n",
       " {'face_box': [199, 318, 143, 199],\n",
       "  'emotion': {'value': 'neutral', 'probability': '1.00'},\n",
       "  'age': {'value': 'young', 'probability': '1.00'},\n",
       "  'sex': {'value': 'male', 'probability': '1.00'}},\n",
       " {'face_box': [525, 446, 173, 223],\n",
       "  'emotion': {'value': 'anger', 'probability': '0.75'},\n",
       "  'age': {'value': 'young', 'probability': '0.93'},\n",
       "  'sex': {'value': 'male', 'probability': '1.00'}}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.face_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
