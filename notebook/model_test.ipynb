{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    \"age_id\":{\n",
    "        0: \"old\",\n",
    "        1: \"middle\",\n",
    "        2: \"young\",\n",
    "        3: \"child\"\n",
    "    },\n",
    "    \"gender_id\":{\n",
    "        0: \"male\",\n",
    "        1: \"female\"\n",
    "    },\n",
    "    \"emotion_id\":{\n",
    "        0: \"neutral\",\n",
    "        1: \"happiness\",\n",
    "        2: \"surprise\",\n",
    "        3: \"anger\",\n",
    "        4: \"sadness\",\n",
    "        5: \"disgust\",\n",
    "        6: \"fear\"\n",
    "    }\n",
    "}\n",
    "IM_WIDTH = 224\n",
    "IM_HEIGHT = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict['gender_alias'] = dict((g,i) for i,g in dataset_dict['gender_id'].items())\n",
    "dataset_dict['age_alias'] = dict((g,i) for i,g in dataset_dict[\"age_id\"].items())\n",
    "dataset_dict['emotion_alias'] = dict((g,i) for i,g in dataset_dict['emotion_id'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_array=None,image_path=None):\n",
    "    \"\"\"\n",
    "    Used for image preprocessing \n",
    "    \"\"\"\n",
    "    if image_array == None: \n",
    "        img = Image.open(image_path)\n",
    "    else:\n",
    "        img  = Image.fromarray(image_array)\n",
    "    img = img.resize((IM_WIDTH,IM_HEIGHT),Image.ANTIALIAS)\n",
    "    img = np.array(img)/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modl = keras.models.load_model(\"/home/andy/Desktop/sken_project/facial_emotion_detection/model/trained_andy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modl.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.randint(-1,1,size=(10,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = modl.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9999988e-01 2.9125587e-07] [9.9996710e-01 3.3707857e-09 3.2904289e-05 1.9254096e-13] [3.0891538e-09 1.4124685e-03 1.3811804e-06 1.5429797e-04 5.2063697e-06\n",
      " 9.9842644e-01 2.6816573e-07]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[9.999940e-01 9.941202e-06] [9.9031234e-01 4.7627598e-08 9.6876258e-03 1.9613473e-12] [2.3565836e-09 4.4553900e-01 6.6203557e-07 7.7044905e-07 1.2819431e-05\n",
      " 5.5444652e-01 1.7877116e-07]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[1.0000000e+00 1.1993156e-08] [9.5963651e-01 3.2180983e-06 4.0360227e-02 9.2935989e-12] [9.1429251e-07 1.2743797e-02 1.1853261e-03 2.5090100e-03 5.4612454e-05\n",
      " 9.8350531e-01 1.1027211e-06]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[1.000000e+00 1.510008e-08] [9.3724102e-01 2.4090877e-08 6.2759027e-02 1.9345788e-12] [2.6639653e-05 8.0282643e-02 3.0771717e-03 2.0273261e-05 5.3411217e-08\n",
      " 9.1659319e-01 6.1694037e-09]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[9.999459e-01 8.941802e-05] [9.9997044e-01 7.7653411e-11 2.9584589e-05 5.8134090e-15] [1.05301119e-08 4.35912807e-06 7.95059314e-05 1.27800695e-05\n",
      " 2.91803104e-07 9.99902010e-01 1.09823702e-06]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[9.9999976e-01 3.1781610e-07] [9.9977881e-01 4.4364867e-07 2.2074449e-04 6.0234326e-13] [4.4237193e-05 2.7136272e-02 1.2585771e-03 3.5701622e-05 9.1625407e-05\n",
      " 9.7141528e-01 1.8239543e-05]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[9.9997723e-01 3.0615043e-05] [7.81855106e-01 4.97106178e-09 2.18144834e-01 1.04065235e-13] [2.5066635e-08 2.1712635e-04 3.9894898e-05 2.9470157e-04 2.7735166e-05\n",
      " 9.9942017e-01 3.0290320e-07]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[9.999956e-01 9.923546e-06] [9.8792636e-01 7.3067646e-08 1.2073549e-02 9.9764294e-11] [3.4442942e-09 7.3094931e-03 1.0081074e-07 4.2451287e-05 3.3357262e-06\n",
      " 9.9264443e-01 8.2957555e-08]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[9.9942386e-01 8.9335442e-04] [9.8837656e-01 1.0502909e-11 1.1623452e-02 4.4699449e-15] [1.3679237e-07 2.2409337e-02 5.3635653e-05 2.9896628e-03 1.6694771e-02\n",
      " 9.5781547e-01 3.6967980e-05]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "[9.9991691e-01 1.5303493e-04] [9.8585147e-01 5.4855949e-08 1.4148535e-02 2.3848330e-12] [1.3293338e-07 8.1138480e-01 1.0036631e-04 3.2732205e-04 4.2547612e-03\n",
      " 1.8108742e-01 2.8452568e-03]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "for gen,age,emotion in zip(result[0],result[1],result[2]):\n",
    "    print(gen,age,emotion)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "with keras.utils.CustomObjectScope({'tf':tf}):\n",
    "    model = keras.models.load_model(\"/home/andy/Desktop/sken_project/facial_emotion_detection/model/keras-facenet/model/facenet_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/home/andy/Desktop/sken_project/facial_emotion_detection/model/keras-facenet/weights/facenet_keras_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
