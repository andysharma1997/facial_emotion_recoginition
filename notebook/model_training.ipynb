{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Genrator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input,Activation,Add\n",
    "from keras.layers import Conv2D,Dense,MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/andy/Desktop/sken_project/facial_emotion_detection/datasets/clean_imfdb.csv\",index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>sex</th>\n",
       "      <th>emotion</th>\n",
       "      <th>age</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leelavathi_1.jpg</td>\n",
       "      <td>female</td>\n",
       "      <td>anger</td>\n",
       "      <td>old</td>\n",
       "      <td>/home/andy/Desktop/sken_project/facial_emotion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leelavathi_10.jpg</td>\n",
       "      <td>female</td>\n",
       "      <td>happiness</td>\n",
       "      <td>old</td>\n",
       "      <td>/home/andy/Desktop/sken_project/facial_emotion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leelavathi_11.jpg</td>\n",
       "      <td>female</td>\n",
       "      <td>anger</td>\n",
       "      <td>old</td>\n",
       "      <td>/home/andy/Desktop/sken_project/facial_emotion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leelavathi_12.jpg</td>\n",
       "      <td>female</td>\n",
       "      <td>anger</td>\n",
       "      <td>old</td>\n",
       "      <td>/home/andy/Desktop/sken_project/facial_emotion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leelavathi_15.jpg</td>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>old</td>\n",
       "      <td>/home/andy/Desktop/sken_project/facial_emotion...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name     sex    emotion  age  \\\n",
       "0   Leelavathi_1.jpg  female      anger  old   \n",
       "1  Leelavathi_10.jpg  female  happiness  old   \n",
       "2  Leelavathi_11.jpg  female      anger  old   \n",
       "3  Leelavathi_12.jpg  female      anger  old   \n",
       "4  Leelavathi_15.jpg  female   surprise  old   \n",
       "\n",
       "                                          image_path  \n",
       "0  /home/andy/Desktop/sken_project/facial_emotion...  \n",
       "1  /home/andy/Desktop/sken_project/facial_emotion...  \n",
       "2  /home/andy/Desktop/sken_project/facial_emotion...  \n",
       "3  /home/andy/Desktop/sken_project/facial_emotion...  \n",
       "4  /home/andy/Desktop/sken_project/facial_emotion...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_name', 'sex', 'emotion', 'age', 'image_path'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.8\n",
    "IM_WIDTH = 480\n",
    "IM_HEIGHT = 640\n",
    "\n",
    "dataset_dict = {\n",
    "    \"age_id\":{\n",
    "        0: \"old\",\n",
    "        1: \"middle\",\n",
    "        2: \"young\",\n",
    "        3: \"child\"\n",
    "    },\n",
    "    \"gender_id\":{\n",
    "        0: \"male\",\n",
    "        1: \"female\"\n",
    "    },\n",
    "    \"emotion_id\":{\n",
    "        0: \"neutral\",\n",
    "        1: \"happiness\",\n",
    "        2: \"surprise\",\n",
    "        3: \"anger\",\n",
    "        4: \"sadness\",\n",
    "        5: \"disgust\",\n",
    "        6: \"fear\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict['gender_alias'] = dict((g,i) for i,g in dataset_dict['gender_id'].items())\n",
    "dataset_dict['age_alias'] = dict((g,i) for i,g in dataset_dict[\"age_id\"].items())\n",
    "dataset_dict['emotion_alias'] = dict((g,i) for i,g in dataset_dict['emotion_id'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age_id': {0: 'old', 1: 'middle', 2: 'young', 3: 'child'},\n",
       " 'gender_id': {0: 'male', 1: 'female'},\n",
       " 'emotion_id': {0: 'neutral',\n",
       "  1: 'happiness',\n",
       "  2: 'surprise',\n",
       "  3: 'anger',\n",
       "  4: 'sadness',\n",
       "  5: 'disgust',\n",
       "  6: 'fear'},\n",
       " 'gender_alias': {'male': 0, 'female': 1},\n",
       " 'age_alias': {'old': 0, 'middle': 1, 'young': 2, 'child': 3},\n",
       " 'emotion_alias': {'neutral': 0,\n",
       "  'happiness': 1,\n",
       "  'surprise': 2,\n",
       "  'anger': 3,\n",
       "  'sadness': 4,\n",
       "  'disgust': 5,\n",
       "  'fear': 6}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImfdbDataGenrator():\n",
    "    \"\"\"\n",
    "    Data generator for IMFDB dataset. This class should be used when training our custom multi output model\n",
    "    \"\"\"\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    \n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(self.df))\n",
    "        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "        \n",
    "        train_up_to = int(train_up_to* TRAIN_TEST_SPLIT)\n",
    "        train_idx,valid_idx = train_idx[:train_up_to],train_idx[train_up_to:]\n",
    "        \n",
    "        #convert alias to id\n",
    "        self.df['gender_id'] = self.df['sex'].map(lambda gen: dataset_dict['gender_alias'][gen])\n",
    "        self.df['age_id'] = self.df['age'].map(lambda age: dataset_dict['age_alias'][age])\n",
    "        self.df['emotion_id'] = self.df['emotion'].map(lambda emo: dataset_dict['emotion_alias'][emo])\n",
    "        return train_idx,valid_idx,test_idx\n",
    "    \n",
    "    def preprocess_image(self,image_path):\n",
    "        \"\"\"\n",
    "        Used for image preprocessing \n",
    "        \"\"\"\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize((IM_WIDTH,IM_HEIGHT),Image.ANTIALIAS)\n",
    "        img = np.array(img)/255.0\n",
    "        return img\n",
    "    def grenerate_images(self,image_idx,is_training,batch_size=16):\n",
    "        \"\"\"\n",
    "        Used to genrate batch with images \n",
    "        \"\"\"\n",
    "        images,ages,emotions,genders = [],[],[],[]\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "                person = self.df.iloc[idx]\n",
    "                age = person['age_id']\n",
    "                emotion = person['emotion_id']\n",
    "                gender = person['gender_id']\n",
    "                file = person['image_path']\n",
    "                im = self.preprocess_image(file)\n",
    "                ages.append(to_categorical(age,len(dataset_dict['age_id'])))\n",
    "                genders.append(to_categorical(gender,len(dataset_dict['gender_id'])))\n",
    "                emotions.append(to_categorical(emotion,len(dataset_dict['emotion_id'])))\n",
    "                images.append(im)\n",
    "                \n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images),[np.array(genders),np.array(ages),np.array(emotions)]\n",
    "                    images,ages,emotions,genders = [],[],[],[]\n",
    "            if not is_training:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImfdbDataGenrator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_name', 'sex', 'emotion', 'age', 'image_path'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx,valid_idx,test_idx = data_gen.generate_split_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_name', 'sex', 'emotion', 'age', 'image_path', 'gender_id',\n",
       "       'age_id', 'emotion_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImfdbOutputModel():\n",
    "    \"\"\"\n",
    "    This class is used to genrate our multi-output model which is a vgg16 with its 4 blocks and then we \n",
    "    add our three output layers with the vgg layers freesed\n",
    "    \"\"\"\n",
    "    def __init__(self,custom_model_path):\n",
    "        self.model = keras.models.load_model(custom_model_path)\n",
    "    def get_model(self):\n",
    "        for layer in self.model.layers[:15]:\n",
    "            layer.trainable = False\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "custom_model_obj = ImfdbOutputModel(\"/home/andy/Desktop/sken_project/facial_emotion_detection/model/custom_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_model_obj.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 640, 480, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 640, 480, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 640, 480, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 320, 240, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 320, 240, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 320, 240, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 160, 120, 128 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 160, 120, 256 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 160, 120, 256 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 160, 120, 256 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 80, 60, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 80, 60, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 80, 60, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 80, 60, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 40, 30, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 614400)       0           block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           39321664    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           39321664    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           39321664    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sex_out (Dense)                 (None, 2)            130         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "age_out (Dense)                 (None, 4)            260         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "emotion (Dense)                 (None, 7)            455         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 125,601,869\n",
      "Trainable params: 117,966,221\n",
      "Non-trainable params: 7,635,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 1e-4\n",
    "epochs =50\n",
    "opt = Adam(lr=init_lr,decay=init_lr/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,\n",
    "             loss={\n",
    "                 \"sex_out\": 'categorical_crossentropy',\n",
    "                 \"age_out\": 'categorical_crossentropy',\n",
    "                 \"emotion\": 'categorical_crossentropy'\n",
    "             },\n",
    "             loss_weights={\n",
    "                 \"sex_out\": 0.1,\n",
    "                 \"age_out\": 1.5,\n",
    "                 \"emotion\": 1.5\n",
    "             },\n",
    "             metrics={\n",
    "                 \"sex_out\": 'categorical_accuracy',\n",
    "                 \"age_out\": 'categorical_accuracy',\n",
    "                 \"emotion\": \"categorical_accuracy\"\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "batch_size = 32\n",
    "valid_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_gen.grenerate_images(train_idx,is_training=True,batch_size=batch_size)\n",
    "valid_gen = data_gen.grenerate_images(valid_idx,is_training=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(\"./model_checkpoint\",monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 84/609 [===>..........................] - ETA: 1:47:39 - loss: 5.5860 - sex_out_loss: 0.7310 - age_out_loss: 1.4505 - emotion_loss: 2.2247 - sex_out_categorical_accuracy: 0.6178 - age_out_categorical_accuracy: 0.4262 - emotion_categorical_accuracy: 0.2128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-86d80d74bf11>\", line 7, in <module>\n",
      "    validation_steps=len(valid_idx)//valid_batch_size)\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1861, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 855, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/andy/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_gen,\n",
    "                             steps_per_epoch=len(train_idx)//batch_size,\n",
    "                              verbose=True,\n",
    "                             epochs=epochs,\n",
    "                             callbacks=callbacks,\n",
    "                             validation_data=valid_gen,\n",
    "                             validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
